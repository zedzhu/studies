# 机器学习损失函数
通常，监督学习的优化目标函数（或者叫代价函数）形式如下[^1]：
$$
\theta^* = \arg \min_\theta (\frac{1}{N}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Omega(\theta) ) \quad \tag{1}
$$
即学习到使得右边式子达到最小值的参数$\theta$的解$\theta^*$。其中，前面部分$L(y_i, f(x_i; \theta))$是第$i$个样本的预测值$f(x_i; \theta)$和真实值$y_i$之间的误差，也即损失函数[^2]。后面的$\Omega(\theta)$是对参数$\theta$的正则化项或者惩罚项，主要用来降低模型的复杂度，避免过拟合。损失函数 *L* 也被称为经验风险，加上正则项后就是结构风险[^3]。我们令$\hat{y_i}=f(x_i; \theta)$，下面分别看一下分类问题和回归问题中的一些常见损失函数。为了简化表示，略去代表第$i$个样本的下标$i$。

## 分类问题
### 1. 0-1损失[^4]
$$
L(y, \hat{y})=\left\{
\begin{aligned}
1, \quad y \neq \hat{y}\\
0, \quad y=\hat{y}
\end{aligned}
\right.
$$
如果是二分类问题，则等价于判断$y$和$\hat{y}$的符号是否相同：
$$
L(y, \hat{y})=\left\{
\begin{aligned}
1, \quad y\hat{y}\le0\\
0, \quad y\hat{y}>0
\end{aligned}
\right.
$$
此时亦等价于[^5]：
$$
L(y, \hat{y})=\frac{1}{2}(1-sign(y\hat{y}))
$$
该损失函数能够直观地刻画分类的错误率，但是非凸、非光滑的特点，在算法上难以优化，0-1损失的一个代理损失函数是Hinge损失函数[^6]。
### 2. Hinge loss
Hinge loss和SVM息息相关[^7]，具体公式如下：
$$
L(y, \hat{y})=max(0, 1-y\hat{y}), \quad y=\pm1
$$
可见，当真实值$y$和预测值$\hat{y}$符号相同时，并且$y\hat{y}\ge1$时，Hinge loss为0；当$y$和$\hat{y}$符号相反时，Hinge loss随着$\hat{y}$的增大而线性增大[^8]。
另外，Hinge loss在$y\hat{y}=1$处不可导，因此不能用梯度下降法进行优化，而是用次梯度下降法(Subgradient Descent Method)[^9]。

### 3. 指数损失Exponential loss[^10]
指数损失函数也是0-1损失函数的一种代理函数：
$$
L(y, \hat{y})=\exp(-y\hat{y})
$$
运用指数损失的典型分类器是AdaBoost算法。

### 4. Logistic损失(log loss)
我们先来看一下Logistic函数。
$$
\begin{gathered}
\sigma(z) = sigmoid(z) = \frac{1}{1+\exp(-z)} \\
\sigma(-z) = 1 - \sigma(z) \tag{4.0}
\end{gathered}
$$
其函数图像：
<div style="text-align:center" markdown="1">

![Sigmoid](assets/sigmoid.png "Sigmoid")
</div>

在$y\in\{-1,1\}$时，log loss形式为：[^9] [^11]
$$
L(y, \hat{y})=\log(1+\exp(-y\hat{y})), \quad y=\pm1 \tag{4.1} 
$$
**注意，其中 $\hat{y}=f(x; \theta)=\theta^\mathrm{T}x$**

在$y\in\{0,1\}$时，log loss形式为：[^12] [^13]
$$
L(y, \hat{y})=-(y\log\sigma(\hat{y})+(1-y)\log(1-\sigma(\hat{y}))), \quad y=0,1 \tag{4.2}
$$
如果我们调整一下 $\hat{y}$ 的定义：$\hat{y}=\sigma(f(x;\theta))=\sigma(\theta^\mathrm{T}x)$，此时其形式就变为我们熟悉的二元交叉熵形式[^14]：
$$
L(y, \hat{y})=-(y\log\hat{y}+(1-y)\log(1-\hat{y})), \quad y=0,1 \tag{4.3}
$$

式$(4.1)$、式$(4.2)$和式$(4.3)$等价，我们来看一下$(4.1)$和$(4.2)$式等价的推导过程。
$(4.1)$式中$y=1$时$(4.2)$式中也有$y=1$, $(4.1)$式化简为：
$$
\begin{aligned}
L(y, \hat{y})=L(1, \hat{y}) &= \log(1+\exp(-\hat{y})) \\
&= -\log\sigma(\hat{y}) \\
&= -\log\sigma(\theta^\mathrm{T}x)
\end{aligned}
$$
$(4.2)$式化简为：
$$
\begin{aligned}
L(y, \hat{y})=L(1, \hat{y}) &= -\log\sigma(\hat{y}) \\
&= -\log\sigma(\theta^\mathrm{T}x)
\end{aligned}
$$
可见当$y$取标签1（正例）时，$(4.1)$和$(4.2)$式相等。
再看当$y$取负例时，此时$(4.1)$式中$y=-1$，$(4.2)$式中$y=0$。$(4.1)$式化简为：
$$
\begin{aligned}
L(y, \hat{y})=L(-1, \hat{y}) &= \log(1+\exp(\hat{y})) \\
&= -\log(\frac{1}{1+\exp(\hat{y})}) \\
&= -\log(\sigma(-\hat{y})) \\
&= -\log(1-\sigma(\hat{y})) \\
&= -\log(1-\sigma(\theta^\mathrm{T}x)) 
\end{aligned}
$$
最后一步是因为$(4.0)$式$\sigma(-z)=1-\sigma(z)$。$(4.2)$式化简为：
$$
\begin{aligned}
L(y, \hat{y})=L(0, \hat{y}) &= -\log(1-\sigma(\hat{y})) \\
&= -\log(1-\sigma(\theta^\mathrm{T}x)) 
\end{aligned}
$$
因此当$y$取负例时$(4.1)$和$(4.2)$式相等，综合起来就是两者等价。
我们现在再来推导一下这个损失函数的由来。
对于$n$个服从i.i.d.分布（独立同分布）的样本$\{x_i,y_i\}$, $x_i$是输入特征向量，$y_i$是真实分类标签并且$y_i\in\{0,1\}$。设随机变量$X$代表输入$x$，随机变量$Y$代表类别标签$y$，我们试图寻找出具体的联合分布$P(X,Y)$以及条件分布$P(Y|X)$（或者连续值情况下的概率密度函数），但是因为我们无法获得所有的样本，输入的复杂性等等原因，我们很难求解没有给出具体分布函数形式的非参数统计(nonparametric)问题。另一方面，我们可以基于经验、数据生成的方式或中心极限定理来猜测具体的分布形式（比如正态分布、0-1伯努利分布、二项分布、泊松分布等），一旦我们做出分布假定，就可以用一组参数$\theta$来确定该分布，所以问题就转为对这组参数$\theta$的估计，也即“分布已知，参数未知”的参数统计(parametric)问题。最大似然估计(maximum-likelihood estimation,MLE)就是其中一种参数估计方法（还有最小方差无偏估计、贝叶斯估计等方法）[^15]。
最大似然的意思就是最为相似，即最大的可能性。对于获得的服从i.i.d.的$n$个样本$\{x_i,y_i\}$，我们假定样本服从某种分布，
找到使以下概率最大化（使该样本结果出现的可能性最大）的参数$\theta$就是最大似然估计：
$$
\arg \max_\theta P(y_1,\cdots,y_n|x_1,\cdots,x_n;\theta)
$$
因为样本服从i.i.d.，所以等价于：
$$
\arg \max_\theta \prod_{i=1}^{n}P(y_i|x_i;\theta)
$$
连续相乘比较复杂，为了简化计算，我们对优化目标取对数$\log$（一般取自然对数$\ln$或者$\log_2$)，因为$\log$严格单调递增，并不影响结果：
$$
\begin{gathered}
L(\theta)=\prod_{i=1}^{n}P(y_i|x_i;\theta)  \\
l(\theta)=\log L(\theta) = \sum_{i=1}^{n}\log P(y_i|x_i;\theta) \quad \tag{4.4}
\end{gathered}
$$
最大化$L(\theta)$和最大化$l(\theta)$是等价的，但是$l(\theta)$是求和计算，简单多了。在逻辑回归二元分类任务中，分类标签$y\in\{0,1\}$，因此我们可以认为数据服从0-1伯努利分布：
$$
y \sim Bernoulli(1,p)
$$
即对于每一个样本的分类标签$y$，为1（正例）的概率$p$，为0（反例）的概率则为$1-p$。因此：
$$
\begin{gathered}
P(y=1|x;\theta)=h_\theta(x) \\
P(y=0|x;\theta)=1-h_\theta(x)
\end{gathered}
$$
上面两个公式可以合并成一个公式：
$$
P(y|x;\theta)=(h_\theta(x))^y*(1-h_\theta(x))^{1-y}
$$
代入到$(4.4)$式中，得：
$$
\begin{aligned}
l(\theta)&=\sum_{i=1}^{n}\log (h_\theta(x_i))^{y_i} * (1-h_\theta(x_i))^{1-y_i} \\
&= \sum_{i=1}^{n}(y_i\log h_\theta(x_i) + (1-y_i)\log (1-h_\theta(x_i))) \quad \tag{4.5}
\end{aligned}
$$
最大化$l(\theta)$相当于最小化$-l(\theta)$，而$h_\theta(x)=\sigma(\theta^\mathrm{T}x)=\hat{y}$，因此$(4.5)$式等价于最小化：
$$
\begin{aligned}
-\sum_{i=1}^{n}(y_i\log \hat{y_i}+(1-y_i)\log (1-\hat{y_i}))
\end{aligned}
$$
最后除以样本的数量$n$，得到平均到每个样本的平均损失使结果更直观：
$$
-\frac{1}{n}\sum_{i=1}^{n}(y_i\log \hat{y_i}+(1-y_i)\log (1-\hat{y_i}))
$$
对于单个样本（去掉下标）损失函数则是：
$$
L(y, \hat{y})=-(y\log \hat{y}+(1-y)\log (1-\hat{y})), \quad y=0,1
$$
这正是$(4.3)$式。至此，log loss的由来推导完毕。

### 5. 交叉熵损失(Cross Entropy)
交叉熵来自于KL散度（Kullback-Leibler (KL) divergence，KL散度也叫相对熵），主要用来度量两个分布的差异，交叉熵越小，差异越小，分布越相似。其形式如下：
$$
L(y, \hat{y})=-\sum_{j=1}^{m}y^j\log \hat{y}^j
$$
注意$y^j,\hat{y}^j$分别表示在$m$类中第$j$类的真实值和预测值，一个样本只能属于$m$个类别中的一个，也就是说这是一个多分类情况下的公式。如果在把$n$个样本考虑进来则损失函数变为：
$$
-\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{m}y_{ij}\log \hat{y_{ij}}
$$
可见，包括从上面第4节log loss的介绍中我们也已经发现，log loss其实是交叉熵损失在二分类情况下的一个特例。
因为只能属于$m$个类别中的1个，也就是真实标签$y_{ij},j\in\{1,\cdots,m\}$只能有一个值为1，其它都是0，因此可以化简为：
$$
-\frac{1}{n}\sum_{i=1}^{n} \log \hat{y_{ij}}
$$
其中，$\hat{y_{ij}}$表示第$i$个样本真实标签值为1的第$j$个分类的预测概率。
对于多分类问题，深度学习神经网络的最后一层通常会加一层softmax层来计算预测概率：
$$
\begin{gathered}
z_i = f(x_i; \theta) \\
\hat{y_i} = softmax(z_i) = \frac{\exp(z_i)}{\sum_{j=1}^{m}\exp(z_j)}, \quad i=1,\cdots,m
\end{gathered}
$$
因此多分类交叉熵经常和softmax函数结合使用。


## 回归问题
### 1、平方损失(Mean Square Error)

### 2、Huber损失

# 深度学习激活函数
### 1、对数几率Sigmoid

### 2、双曲正切Tanh

### 3、修正线性单元ReLu

[^1]: http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/，开头部分 
[^2]: https://blog.csdn.net/zouxy09/article/details/24971995
[^3]: 《统计学习方法 第2版》P18，李航
[^4]: 《统计学习方法 第2版》P16，李航
[^5]: https://blog.csdn.net/google19890102/article/details/50522945，第1部分
[^6]: 《百面机器学习》P142，葫芦娃
[^7]: http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/，第四部分
[^8]: https://www.cnblogs.com/hejunlin1992/p/8158933.html
[^9]: 《百面机器学习》P143，葫芦娃
[^10]: https://blog.csdn.net/google19890102/article/details/50522945，第4部分
[^11]: http://www.hongliangjie.com/wp-content/uploads/2011/10/logistic.pdf, 第3节Logistic Loss
[^12]: https://blog.csdn.net/walilk/article/details/51107380
[^13]: https://blog.csdn.net/google19890102/article/details/50522945, 第2部分
[^14]: https://blog.csdn.net/u012223913/article/details/75112246
[^15]: 《程序员的数学-概率统计》，第6章